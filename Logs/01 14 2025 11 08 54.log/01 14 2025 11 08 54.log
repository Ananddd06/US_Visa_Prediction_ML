[ 2025-01-14 11:08:54,542 ] 160 numexpr.utils - INFO - NumExpr defaulting to 8 threads.
[ 2025-01-14 11:08:56,028 ] 18 root - INFO - Entered the start_data_ingestion of the TrainPipeline Class
[ 2025-01-14 11:08:56,028 ] 19 root - INFO - Getting the data from MongoDB
[ 2025-01-14 11:08:56,028 ] 55 root - INFO - Initiating Data Ingestion
[ 2025-01-14 11:08:56,028 ] 23 root - INFO - Exporting data into MongoDb
[ 2025-01-14 11:08:56,400 ] 29 root - INFO - Database connection is successful
[ 2025-01-14 11:09:03,701 ] 26 root - INFO - Shape of the dataset: (25480, 12)
[ 2025-01-14 11:09:03,702 ] 30 root - INFO - Saving exported data into feature store file path: artifact/01_14_2025_11_08_55/data_ingestion/feature_store/usvisa.csv
[ 2025-01-14 11:09:03,797 ] 59 root - INFO - Got the data from MongoDB
[ 2025-01-14 11:09:03,797 ] 37 root - INFO - Entered split_data_as_train_and_test method of the Data Ingestion class
[ 2025-01-14 11:09:03,803 ] 41 root - INFO - Split the data frame successfully
[ 2025-01-14 11:09:03,803 ] 47 root - INFO - Exporting the data frame into train and test data frames
[ 2025-01-14 11:09:03,907 ] 50 root - INFO - Exported the data frame into train and test datasets
[ 2025-01-14 11:09:03,909 ] 63 root - INFO - Executed the train-test split
[ 2025-01-14 11:09:03,909 ] 64 root - INFO - Exited initiate_data_ingestion method of DataIngestion class
[ 2025-01-14 11:09:03,909 ] 71 root - INFO - Data ingestion artifact: DataIngestionArtifact(trained_file_path='artifact/01_14_2025_11_08_55/data_ingestion/ingested/train.csv', test_file_path='artifact/01_14_2025_11_08_55/data_ingestion/ingested/test.csv')
[ 2025-01-14 11:09:03,914 ] 22 root - INFO - Got the train and the test set from MongoDB
[ 2025-01-14 11:09:03,914 ] 23 root - INFO - Excited about the Data Ingestion workflow
[ 2025-01-14 11:09:03,914 ] 29 root - INFO - Entered the start_data_validation of the TrainPipeline Class
[ 2025-01-14 11:09:03,917 ] 101 root - INFO - Started the Data Validation flow
[ 2025-01-14 11:09:03,953 ] 110 root - INFO - Training DataFrame shape: (20384, 12)
[ 2025-01-14 11:09:03,953 ] 111 root - INFO - Testing DataFrame shape: (5096, 12)
[ 2025-01-14 11:09:03,953 ] 28 root - INFO - Is required column present: True
[ 2025-01-14 11:09:03,953 ] 115 root - INFO - All required columns present in training dataframe: True
[ 2025-01-14 11:09:03,953 ] 28 root - INFO - Is required column present: True
[ 2025-01-14 11:09:03,953 ] 120 root - INFO - All required columns present in testing dataframe: True
[ 2025-01-14 11:09:03,954 ] 91 root - INFO - No drift detected in numerical columns.
[ 2025-01-14 11:09:03,954 ] 150 root - INFO - Data validation artifact: DataValidationArtifact(validation_status=True, message='Drift not detected', drift_report_file_path='artifact/01_14_2025_11_08_55/data_validation/drift_report/report.yaml')
[ 2025-01-14 11:09:03,955 ] 36 root - INFO - Performed the data validation operation
[ 2025-01-14 11:09:03,955 ] 37 root - INFO - Exited the start_data_validation method of TrainPipeline class
[ 2025-01-14 11:09:03,955 ] 43 root - INFO - Entered the start_data_transformation of the TrainPipeline Class
[ 2025-01-14 11:09:03,958 ] 76 root - INFO - Starting data transformation.
[ 2025-01-14 11:09:03,958 ] 42 root - INFO - Entered the data transformer object creation.
[ 2025-01-14 11:09:03,958 ] 56 root - INFO - Setting up ColumnTransformer.
[ 2025-01-14 11:09:03,958 ] 66 root - INFO - Preprocessor object created successfully.
[ 2025-01-14 11:09:03,993 ] 82 root - INFO - Splitting input and target features for train and test datasets.
[ 2025-01-14 11:09:03,996 ] 83 root - INFO - Entered drop column of the Utils
[ 2025-01-14 11:09:03,997 ] 86 root - INFO - Exited the drop columns of the method Utils
[ 2025-01-14 11:09:03,998 ] 83 root - INFO - Entered drop column of the Utils
[ 2025-01-14 11:09:03,998 ] 86 root - INFO - Exited the drop columns of the method Utils
